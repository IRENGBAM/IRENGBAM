{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNT5ImAusSWpWdnennh8hMX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IRENGBAM/IRENGBAM/blob/main/cbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqriDKZ5G2Vr"
      },
      "source": [
        "# importing modules\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import save_model\n",
        "\n",
        "\n",
        "# importing training data\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "training_data = pd.read_csv(\"training_data.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuQikylxGD2g"
      },
      "source": [
        "\n",
        "\n",
        "# preprocessing training data\n",
        "training_data[\"patterns\"] = training_data[\"patterns\"].str.lower()\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
        "training_data_tfidf = vectorizer.fit_transform(training_data[\"patterns\"]).toarray()\n",
        "\n",
        "# preprocessing target variable(tags)\n",
        "le = LabelEncoder()\n",
        "training_data_tags_le = pd.DataFrame({\"tags\": le.fit_transform(training_data[\"tags\"])})\n",
        "training_data_tags_dummy_encoded = pd.get_dummies(training_data_tags_le[\"tags\"]).to_numpy()\n",
        "\n",
        "# creating DNN\n",
        "edubot = Sequential()\n",
        "edubot.add(Dense(10, input_shape=(len(training_data_tfidf[0]),)))\n",
        "edubot.add(Dense(8))\n",
        "edubot.add(Dense(8))\n",
        "edubot.add(Dense(6))\n",
        "edubot.add(Dense(len(training_data_tags_dummy_encoded[0]), activation=\"softmax\"))\n",
        "edubot.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# fitting DNN\n",
        "edubot.fit(training_data_tfidf, training_data_tags_dummy_encoded, epochs=50, batch_size=32)\n",
        "\n",
        "# saving model file\n",
        "save_model(edubot, \"EduBot_v2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b-8mQtUGZUc"
      },
      "source": [
        "# importing modules\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import json\n",
        "import random\n",
        "\n",
        "\n",
        "# importing training data\n",
        "training_data = pd.read_csv(\"training_data_EduBot_v2.csv\")\n",
        "\n",
        "# loading model\n",
        "edubot_v2 = load_model(\"EduBot_v2\")\n",
        "\n",
        "# importing responses\n",
        "responses = json.load(open(\"responses.json\", \"r\"))\n",
        "\n",
        "\n",
        "# fitting TfIdfVectorizer with training data to preprocess inputs\n",
        "training_data[\"patterns\"] = training_data[\"patterns\"].str.lower()\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
        "vectorizer.fit(training_data[\"patterns\"])\n",
        "\n",
        "\n",
        "# fitting LabelEncoder with target variable(tags) for inverse transformation of predictions\n",
        "le = LabelEncoder()\n",
        "le.fit(training_data[\"tags\"])\n",
        "\n",
        "\n",
        "# preprocessing input\n",
        "def predict_tag(inp_str):\n",
        "    inp_data_tfidf = vectorizer.transform([inp_str.lower()]).toarray()\n",
        "    predicted_proba = edubot_v2.predict(inp_data_tfidf)\n",
        "    encoded_label = [np.argmax(predicted_proba)]\n",
        "    predicted_tag = le.inverse_transform(encoded_label)[0]\n",
        "    return predicted_tag\n",
        "\n",
        "\n",
        "# chat function\n",
        "def start_chat():\n",
        "    print(\"---------------  EduBot_v2 - AI Chat bot  ---------------\")\n",
        "    print(\"Ask any queries regarding SASTRA...\")\n",
        "    print(\"I will try to understand you and reply...\")\n",
        "    print(\"Type EXIT to quit...\")\n",
        "    while True:\n",
        "        inp = input(\"Ask anything... : \")\n",
        "        if inp == \"EXIT\":\n",
        "            break\n",
        "        else:\n",
        "            if inp:\n",
        "                tag = predict_tag(inp)\n",
        "                response = random.choice(responses[tag])\n",
        "                print(\"Response... : \", response)\n",
        "            else:\n",
        "                pass\n",
        "\n",
        "# calling chat function to check functionality of the program\n",
        "start_chat()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spNOdwkDHBIb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}